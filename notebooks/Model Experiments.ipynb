{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "os.chdir(\"../scripts/\")\n",
    "import model\n",
    "import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack\n",
    "\n",
    "import sklearn\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.feature_selection import SelectPercentile, chi2\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OrdinalEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Prep Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = data.load_source()\n",
    "m = model.load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>description</th>\n",
       "      <th>amount</th>\n",
       "      <th>tags</th>\n",
       "      <th>notes</th>\n",
       "      <th>type</th>\n",
       "      <th>check</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-19</td>\n",
       "      <td>Monthly Maintenance Fee</td>\n",
       "      <td>-12.00</td>\n",
       "      <td>Bank</td>\n",
       "      <td></td>\n",
       "      <td>Checking</td>\n",
       "      <td>2881.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-19</td>\n",
       "      <td>STOP &amp; SHOP 0867 HIGHLAND PK NJ</td>\n",
       "      <td>-24.43</td>\n",
       "      <td>Groceries</td>\n",
       "      <td></td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>2382.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-20</td>\n",
       "      <td>NETFLIX.COM NETFLIX.COM CA</td>\n",
       "      <td>-10.68</td>\n",
       "      <td>Media</td>\n",
       "      <td></td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>2383.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-23</td>\n",
       "      <td>STOP &amp; SHOP 0867 HIGHLAND PK NJ</td>\n",
       "      <td>-70.15</td>\n",
       "      <td>Groceries</td>\n",
       "      <td></td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>2385.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-23</td>\n",
       "      <td>STOP &amp; SHOP 0867 HIGHLAND PK NJ</td>\n",
       "      <td>-20.29</td>\n",
       "      <td>Groceries</td>\n",
       "      <td></td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>2384.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date                      description  amount       tags notes  \\\n",
       "0 2017-01-19          Monthly Maintenance Fee  -12.00       Bank         \n",
       "1 2017-01-19  STOP & SHOP 0867 HIGHLAND PK NJ  -24.43  Groceries         \n",
       "2 2017-01-20       NETFLIX.COM NETFLIX.COM CA  -10.68      Media         \n",
       "3 2017-01-23  STOP & SHOP 0867 HIGHLAND PK NJ  -70.15  Groceries         \n",
       "4 2017-01-23  STOP & SHOP 0867 HIGHLAND PK NJ  -20.29  Groceries         \n",
       "\n",
       "          type   check  \n",
       "0     Checking  2881.0  \n",
       "1  Credit Card  2382.0  \n",
       "2  Credit Card  2383.0  \n",
       "3  Credit Card  2385.0  \n",
       "4  Credit Card  2384.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_source = source[(source.date.dt.year >= 2019)]\n",
    "tag_counts = test_source.tags.value_counts()\n",
    "test_source = test_source[(test_source.tags.isin(tag_counts[tag_counts > 30].index))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(test_source, test_source.tags, test_size=.20, random_state=376)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build and Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = ColumnTransformer([('description', TfidfVectorizer(ngram_range=(1,1)), \"description\"),\n",
    "                        ('amount', StandardScaler(), [\"amount\"]),\n",
    "                        ('type', OrdinalEncoder(), [\"type\"]) \n",
    "                       ])\n",
    "xgb_pipe = Pipeline([('column_trans', ct),\n",
    "#                   ('chi2_filter', SelectPercentile(chi2, percentile=75)),\n",
    "#                   ('mlp', MLPClassifier(hidden_layer_sizes=(250, 250, 250)))]\n",
    "                 ('xgboost', GradientBoostingClassifier(n_estimators=150))])\n",
    "\n",
    "mlp_pipe = Pipeline([('column_trans', ct),\n",
    "#                   ('chi2_filter', SelectPercentile(chi2, percentile=75)),\n",
    "                  ('mlp', MLPClassifier(hidden_layer_sizes=(250, 250, 250)))])\n",
    "#                  ('xgboost', GradientBoostingClassifier(n_estimators=150))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = mlp_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'fit_time': array([3.62199211, 3.02642202, 3.13421631, 3.47611094, 2.62195015]),\n",
       "  'score_time': array([0.00848413, 0.0086751 , 0.00855184, 0.00850105, 0.00853205]),\n",
       "  'test_score': array([0.91519435, 0.91872792, 0.92226148, 0.91843972, 0.90070922])},\n",
       " 0.9150665363506503)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = cross_validate(pipe, train_x, train_y)\n",
    "cv, cv['test_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9322033898305084"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(train_x, train_y)\n",
    "pipe.score(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "\n",
    "# with open('../data/model.pickle', 'wb') as f:\n",
    "#     pickle.dump(model, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Analyze Test Results, Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eval = test_x.copy()\n",
    "test_eval[\"prob\"]= pipe.predict_proba(test_x).max(axis=1)\n",
    "test_eval[\"pred\"] = pipe.predict(test_x)\n",
    "test_eval[\"act\"] = test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Amazon             NaN\n",
       "Bill          0.950000\n",
       "Car           0.833333\n",
       "Cash               NaN\n",
       "Charity       0.846154\n",
       "Clothing      0.833333\n",
       "Costco             NaN\n",
       "Food          0.894737\n",
       "Gas                NaN\n",
       "Groceries     0.967742\n",
       "Home               NaN\n",
       "Housing            NaN\n",
       "Income             NaN\n",
       "Media         0.936170\n",
       "Nasya              NaN\n",
       "Phone              NaN\n",
       "Therapy            NaN\n",
       "Transition    0.900000\n",
       "Utilities     0.937500\n",
       "Work, Food    0.864865\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors = test_eval[test_eval.pred != test_eval.act].sort_values(\"prob\")\n",
    "(test_eval.tags.value_counts() - errors.act.value_counts())/test_eval.tags.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(ColumnTransformer(transformers=[('description', TfidfVectorizer(),\n",
       "                                  'description'),\n",
       "                                 ('amount', StandardScaler(), ['amount']),\n",
       "                                 ('type', OrdinalEncoder(), ['type'])]),\n",
       " MLPClassifier(hidden_layer_sizes=(250, 250, 250)))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder, clf = list(pipe.named_steps.values())\n",
    "tfidf = list(encoder.named_transformers_.values())[0]\n",
    "encoder, clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_source = source[source.date.dt.year >= 2019]\n",
    "sparse_features = encoder.transform(training_source)\n",
    "df = pd.DataFrame(sparse_features.toarray()[:,:-2], columns=tfidf.get_feature_names(), index=training_source.index)\n",
    "df[\"tags\"] = training_source.tags\n",
    "df.index = training_source.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amazon \n",
      "==============\n",
      "amzn         0.695855\n",
      "204rz9e71    0.644228\n",
      "2r49o5431    0.644228\n",
      "ms0tn2np1    0.644228\n",
      "9o8uv81u3    0.644228\n",
      "dtype: object\n",
      "\n",
      "Amazon, Media \n",
      "==============\n",
      "video    0.430633\n",
      "3080     0.426292\n",
      "802      0.426292\n",
      "wa       0.414522\n",
      "888       0.38444\n",
      "dtype: object\n",
      "\n",
      "Beep Boop \n",
      "==============\n",
      "store         1.0\n",
      "mn        0.84483\n",
      "depot    0.835619\n",
      "888      0.535035\n",
      "800      0.478244\n",
      "dtype: object\n",
      "\n",
      "Bill \n",
      "==============\n",
      "payment            1.0\n",
      "chk           0.579403\n",
      "from          0.575383\n",
      "3294          0.529057\n",
      "0159243502    0.524058\n",
      "dtype: object\n",
      "\n",
      "Books \n",
      "==============\n",
      "ny           1.0\n",
      "wa      0.785743\n",
      "866     0.618553\n",
      "id      0.395824\n",
      "inst    0.375609\n",
      "dtype: object\n",
      "\n",
      "Car \n",
      "==============\n",
      "172                 0.839851\n",
      "in                  0.798689\n",
      "princetonparking    0.786574\n",
      "800                 0.772043\n",
      "lyft                0.738866\n",
      "dtype: object\n",
      "\n",
      "Cash \n",
      "==============\n",
      "park         0.567725\n",
      "27           0.440389\n",
      "31           0.437169\n",
      "square       0.431678\n",
      "000002936    0.427559\n",
      "dtype: object\n",
      "\n",
      "Charity \n",
      "==============\n",
      "11         0.694672\n",
      "city       0.680407\n",
      "gofndme    0.641936\n",
      "redwood    0.610986\n",
      "707        0.597696\n",
      "dtype: object\n",
      "\n",
      "Clothing \n",
      "==============\n",
      "everlane    0.844519\n",
      "tomboyx     0.832444\n",
      "freehold    0.807455\n",
      "toms        0.768616\n",
      "717         0.641307\n",
      "dtype: object\n",
      "\n",
      "Costco \n",
      "==============\n",
      "0322           0.600614\n",
      "bridgewater    0.529495\n",
      "0323           0.513677\n",
      "whse           0.503055\n",
      "costco         0.493414\n",
      "dtype: object\n",
      "\n",
      "Drugs \n",
      "==============\n",
      "2561      0.567527\n",
      "aid        0.43957\n",
      "rite       0.43957\n",
      "store     0.375003\n",
      "parknj    0.308573\n",
      "dtype: object\n",
      "\n",
      "Food \n",
      "==============\n",
      "ny                 1.0\n",
      "lawrence           1.0\n",
      "609           0.936405\n",
      "piscataway    0.882506\n",
      "boom          0.861876\n",
      "dtype: object\n",
      "\n",
      "Gas \n",
      "==============\n",
      "sunoco        0.956221\n",
      "57703         0.646634\n",
      "57323         0.642662\n",
      "0001544605    0.625983\n",
      "47679840      0.609594\n",
      "dtype: object\n",
      "\n",
      "Gift \n",
      "==============\n",
      "ca                      1.0\n",
      "charlottesvilva    0.853485\n",
      "parknj             0.794502\n",
      "ny                 0.766992\n",
      "877                0.676887\n",
      "dtype: object\n",
      "\n",
      "Groceries \n",
      "==============\n",
      "edison       0.782912\n",
      "franklin     0.756888\n",
      "02            0.75661\n",
      "brunswinj    0.712379\n",
      "north        0.701795\n",
      "dtype: object\n",
      "\n",
      "HSA \n",
      "==============\n",
      "id      0.679019\n",
      "ppd     0.439812\n",
      "des      0.33951\n",
      "indn     0.33951\n",
      "co      0.339065\n",
      "dtype: object\n",
      "\n",
      "Home \n",
      "==============\n",
      "ikea         0.951485\n",
      "elizabeth    0.877138\n",
      "00011510     0.673719\n",
      "00692        0.666886\n",
      "00011528      0.61789\n",
      "dtype: object\n",
      "\n",
      "Housing \n",
      "==============\n",
      "e1ad9abb5    0.642089\n",
      "91ddfc41c    0.642089\n",
      "x2phom09q    0.642089\n",
      "d72891fa5    0.642089\n",
      "piq90nwip    0.642089\n",
      "dtype: object\n",
      "\n",
      "Income \n",
      "==============\n",
      "bankamerideals    0.707107\n",
      "cashback          0.707107\n",
      "mobile            0.637771\n",
      "xxxxx69054        0.517995\n",
      "xxxxx68775        0.517995\n",
      "dtype: object\n",
      "\n",
      "Media \n",
      "==============\n",
      "netflix    0.831733\n",
      "nytimes    0.782847\n",
      "ca         0.757973\n",
      "5797172    0.666231\n",
      "com        0.652286\n",
      "dtype: object\n",
      "\n",
      "Medical \n",
      "==============\n",
      "university    0.784411\n",
      "llc           0.713222\n",
      "park          0.674534\n",
      "parknj        0.586537\n",
      "2561          0.567527\n",
      "dtype: object\n",
      "\n",
      "Nasya \n",
      "==============\n",
      "28de3050d    0.642089\n",
      "3b2aa5d6e    0.642089\n",
      "d553c3621    0.642089\n",
      "06699833e    0.596855\n",
      "bd4d402fb    0.596855\n",
      "dtype: object\n",
      "\n",
      "Phone \n",
      "==============\n",
      "att     0.591309\n",
      "2775    0.479898\n",
      "676     0.479898\n",
      "3650     0.44389\n",
      "721      0.44389\n",
      "dtype: object\n",
      "\n",
      "Savings \n",
      "==============\n",
      "capital    0.663407\n",
      "id         0.448718\n",
      "web        0.291272\n",
      "thomas     0.264311\n",
      "tyrrell     0.23014\n",
      "dtype: object\n",
      "\n",
      "Student Loans \n",
      "==============\n",
      "id         0.599879\n",
      "ppd        0.388552\n",
      "thomas     0.353351\n",
      "tyrrell    0.307667\n",
      "des         0.29994\n",
      "dtype: object\n",
      "\n",
      "Taxes \n",
      "==============\n",
      "irs        0.604086\n",
      "id         0.478056\n",
      "ppd        0.309645\n",
      "thomas     0.281592\n",
      "tyrrell    0.245186\n",
      "dtype: object\n",
      "\n",
      "Therapy \n",
      "==============\n",
      "mobile           0.766314\n",
      "xxxxx16109346    0.563818\n",
      "xxxxx16115212    0.563818\n",
      "xxxxx16255       0.563818\n",
      "xxxxx28593       0.563818\n",
      "dtype: object\n",
      "\n",
      "Transition \n",
      "==============\n",
      "walgreens    0.912542\n",
      "183          0.839851\n",
      "174          0.839851\n",
      "190          0.839851\n",
      "189          0.839851\n",
      "dtype: object\n",
      "\n",
      "Utilities \n",
      "==============\n",
      "181        0.839851\n",
      "186        0.839851\n",
      "check      0.542817\n",
      "billpay    0.505606\n",
      "breach     0.474533\n",
      "dtype: object\n",
      "\n",
      "Vacation \n",
      "==============\n",
      "va                      1.0\n",
      "tx                      1.0\n",
      "nj                      1.0\n",
      "charlottesvilva         1.0\n",
      "king               0.750122\n",
      "dtype: object\n",
      "\n",
      "Vet \n",
      "==============\n",
      "central       0.951485\n",
      "brunswicnj    0.713283\n",
      "east          0.700876\n",
      "cashout       0.532183\n",
      "id            0.409598\n",
      "dtype: object\n",
      "\n",
      "Work, Commute \n",
      "==============\n",
      "pa                   1.0\n",
      "mobile          0.924568\n",
      "york            0.622242\n",
      "philadelphia    0.601637\n",
      "new             0.580164\n",
      "dtype: object\n",
      "\n",
      "Work, Food \n",
      "==============\n",
      "montclair     0.801855\n",
      "piscataway     0.78968\n",
      "naf            0.74423\n",
      "bread         0.629837\n",
      "york          0.622242\n",
      "dtype: object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tag_dicts = dict(iter(df.groupby(\"tags\")))\n",
    "\n",
    "for t in df.tags.sort_values().unique():\n",
    "    print(t, \"\\n==============\")\n",
    "    tag_df = tag_dicts[t]\n",
    "    print(tag_df[tag_df!=0].dropna(axis=1, how=\"all\").max(axis=0).drop(\"tags\").sort_values(ascending=False)[:5])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date                                         2021-08-27 00:00:00\n",
       "description    INFOSYS LIMITED DES:PAYROLL ID:XAW000000767199...\n",
       "amount                                                   1147.41\n",
       "tags                                                      Income\n",
       "notes                                                           \n",
       "type                                                    Checking\n",
       "check                                                   32775.74\n",
       "Name: 3367, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = source.iloc[3367]\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'transformers': [('description', TfidfVectorizer(), 'description'),\n",
       "  ('amount', StandardScaler(), ['amount']),\n",
       "  ('type', OrdinalEncoder(), ['type'])],\n",
       " 'remainder': 'drop',\n",
       " 'sparse_threshold': 0.3,\n",
       " 'n_jobs': None,\n",
       " 'transformer_weights': None,\n",
       " 'verbose': False,\n",
       " '_feature_names_in': array(['date', 'description', 'amount', 'tags', 'notes', 'type', 'check'],\n",
       "       dtype=object),\n",
       " 'n_features_in_': 7,\n",
       " '_columns': ['description', ['amount'], ['type']],\n",
       " '_has_str_cols': True,\n",
       " '_df_columns': Index(['date', 'description', 'amount', 'tags', 'notes', 'type', 'check'], dtype='object'),\n",
       " '_n_features': 7,\n",
       " '_remainder': ('remainder', 'drop', [0, 3, 4, 6]),\n",
       " 'sparse_output_': True,\n",
       " 'transformers_': [('description', TfidfVectorizer(), 'description'),\n",
       "  ('amount', StandardScaler(), ['amount']),\n",
       "  ('type', OrdinalEncoder(), ['type']),\n",
       "  ('remainder', 'drop', [0, 3, 4, 6])]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_char_ngrams',\n",
       " '_char_wb_ngrams',\n",
       " '_check_n_features',\n",
       " '_check_params',\n",
       " '_check_stop_words_consistency',\n",
       " '_check_vocabulary',\n",
       " '_count_vocab',\n",
       " '_get_param_names',\n",
       " '_get_tags',\n",
       " '_limit_features',\n",
       " '_more_tags',\n",
       " '_repr_html_',\n",
       " '_repr_html_inner',\n",
       " '_repr_mimebundle_',\n",
       " '_sort_features',\n",
       " '_stop_words_id',\n",
       " '_tfidf',\n",
       " '_validate_data',\n",
       " '_validate_params',\n",
       " '_validate_vocabulary',\n",
       " '_warn_for_unused_params',\n",
       " '_white_spaces',\n",
       " '_word_ngrams',\n",
       " 'analyzer',\n",
       " 'binary',\n",
       " 'build_analyzer',\n",
       " 'build_preprocessor',\n",
       " 'build_tokenizer',\n",
       " 'decode',\n",
       " 'decode_error',\n",
       " 'dtype',\n",
       " 'encoding',\n",
       " 'fit',\n",
       " 'fit_transform',\n",
       " 'fixed_vocabulary_',\n",
       " 'get_feature_names',\n",
       " 'get_params',\n",
       " 'get_stop_words',\n",
       " 'idf_',\n",
       " 'input',\n",
       " 'inverse_transform',\n",
       " 'lowercase',\n",
       " 'max_df',\n",
       " 'max_features',\n",
       " 'min_df',\n",
       " 'ngram_range',\n",
       " 'norm',\n",
       " 'preprocessor',\n",
       " 'set_params',\n",
       " 'smooth_idf',\n",
       " 'stop_words',\n",
       " 'stop_words_',\n",
       " 'strip_accents',\n",
       " 'sublinear_tf',\n",
       " 'token_pattern',\n",
       " 'tokenizer',\n",
       " 'transform',\n",
       " 'use_idf',\n",
       " 'vocabulary',\n",
       " 'vocabulary_']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['infosys',\n",
       " 'limited',\n",
       " 'des',\n",
       " 'payroll',\n",
       " 'id',\n",
       " 'xaw000000767199',\n",
       " 'indn',\n",
       " 'tyrrell',\n",
       " 'thomas',\n",
       " 'co',\n",
       " 'id',\n",
       " 'xxxxx60235',\n",
       " 'ppd']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.build_analyzer()(example.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'infosys limited des:payroll id:xaw000000767199 indn:tyrrell,thomas co id:xxxxx60235 ppd'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.build_preprocessor()(example.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['INFOSYS',\n",
       " 'LIMITED',\n",
       " 'DES',\n",
       " 'PAYROLL',\n",
       " 'ID',\n",
       " 'XAW000000767199',\n",
       " 'INDN',\n",
       " 'TYRRELL',\n",
       " 'THOMAS',\n",
       " 'CO',\n",
       " 'ID',\n",
       " 'XXXXX60235',\n",
       " 'PPD']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.build_tokenizer()(example.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'INFOSYS LIMITED DES:PAYROLL ID:XAW000000767199 INDN:TYRRELL,THOMAS CO ID:XXXXX60235 PPD'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
